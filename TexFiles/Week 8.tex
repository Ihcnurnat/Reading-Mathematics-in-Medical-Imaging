\section{Week 8.}
    
Here are some notes for Stein's textbook in Fourier anlysis \cite{stein2011fourier}.

\subsection{Chapter 5.1}

\begin{definition}[Chapter 5, Page 131 Stein]
    We say that a funciton defined on $\mathbb R$ to be of moderate decrease if $f$ cotinuous and there exists a constant $A>0$ so that 
    \[\vert f(x)\vert \leq \frac{A}{1+x^2} ~\text{ for all }~ x\in\mathbb R.\] We shall denote by $\mathcal M(\mathbb R)$ the set of functions of moderate decrease on $\mathbb R$. 
\end{definition}

The inequality condition forces $f$ to be bounded. Also that it decays at infinity at least as fast as $1/x^2$.

\begin{question}
    Connection between moderate decrease with $L^1$, $L^2$, etc?
\end{question}

Under the usual point-wise addition and multiplication, $\mathcal M(\mathbb R)$ is a vector space over $\mathbb C$ \todo{why?}.

Here we give some examples.
\begin{example}
    Both $1/(1+\vert x\vert^n)$ and $e^{-a \vert x\vert}$ are of moderate decrease for $n\geq 2$.
\end{example}

The reason we introduce $\mathcal M(\mathbb R)$ is because we can therefore define 
\[\int_{-\infty}^{\infty}f(x)\,dx=\lim_{N\to\infty}\int_N^N f(x)\,dx.\]

The limit exists, and it could be proved by Cauchy sequence argument. This argument is essentially the same as the process where we tried to define Fourier transform for function in $L^2(\mathbb R)$. 

Here we summarise some properties of moderate decrease functions defined on $\mathbb R$. 
\begin{proposition}[Chapter 5 Proposition 1.1.]
    The integral of a function of moderate decrease defined as 
    \[\int_{-\infty}^{\infty}f(x)\,dx=\lim_{N\to\infty}\int_N^N f(x)\,dx\] 
    satisfies the following properties:
    \begin{itemize}
        \item \textit{Linearity}
        \item \textit{Translation invariance}
        \item \textit{Scaling under dilations}
        \item \textit{Continuity}
    \end{itemize}
\end{proposition}

TODO: Give a proof for \ref{thm_Finversion}......

Back to Epstein's Book.
\subsection{Convolution}

Our interest is to study a smooth function of one variable with data contaminated by noise. And we let $n$ be the function that "\textit{models}" the noise. This Noise function $n$, is typically represented by a rapidly varying function that is \textit{locally of mean zero}.
\begin{definition}
    We say a rapidly varying function is \textit{locally of mean zero} if for any $x$, and a large enought $\delta$, the average 
    \[\frac{1}{\delta}\int_{x}^{x+\delta} n(y)\,dy\]
    is small compared to the size of $n$.
\end{definition}

\begin{question}
    How do we define size of $n$?
\end{question}

\begin{definition}
    The \textit{moving average} of $f$ is defined to be 
    \[\mathcal M_{\delta}(f)(x)=\frac{1}{\delta}\int_{x}^{x+\delta}f(y)\,dy.\]
\end{definition}

In practice of medical image we only consider convolution in lower dimension, but we can actually define it generally.
\begin{definition}[Definition 5.1.1.]
    If $f$ is an $L^1$-function defined on $\mathbb R^n$ and $g$ is a bounded, locally integrable function then, the \textit{convolution product} of $f$ and $g$ iis the function on $\mathbb R^n$ defined by the integral 
    \[f\ast g(\mathbf x)=\int_{\mathbb R^n}f(\mathbf x-\mathbf y)g(\mathbf y)\, d\mathbf y.\] 
\end{definition}

This definition is crafted specifically for Theorem 5.1.1. \ref, see Exercise 5.1.8. \ref{}

\begin{Exercise}[5.1.8.]
    Suppose that the convolution product were defined by \[f\ast g(\mathbf x)=\int f(\mathbf y)g(\mathbf y-\mathbf x)\,d\mathbf y.\] Show that equation of Theorem 5.1.1. would not hold. What would replace it?
\end{Exercise}

\begin{remark}[Remark 5.1.1.]

\end{remark}